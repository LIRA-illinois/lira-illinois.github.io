---
title: "Contraction Actor-Critic: Contraction Metric-Guided Reinforcement Learning for Robust Path Tracking"
date: 2025-05-28
imageUrl: '/src/assets/research/carl.gif'
imageAlt: "A robot following a reference trajectory."
# funding: "ONR N00014-20-1-2249"
# fundingSlugs: ["onr.png"]
citation: "arXiv'25"
projects: ["explainable-verifiable-learning"]
paperUrl: '/files/carl.pdf'
---

<!-- <figure-full-caption>
	<a href="{{ site.url }}{{ site.baseurl }}/assets/images/research/lcss-search.png"><img src="{{ site.url }}{{ site.baseurl }}/assets/images/research/lcss-search.png"></a>
	<figcaption>A partial trace of our search method with weighted Kullback-Leibler (KL) divergence values used to determine which nodes to expand.</figcaption>
</figure-full-caption> -->

<!-- This work proposes a greedy search over a class of **temporal logic formulae** to infer human-interpretable explanations of reinforcement learning policies. See our IEEE Control Systems Letters paper for more details. -->

<!-- <div class="row">
	<a href="https://arxiv.org/pdf/2309.16960" class="button_general">arXiv</a>
	<a href="https://doi.org/10.1109/LCSYS.2024.3519301" class="button_general">DOI</a>
</div> --> -->