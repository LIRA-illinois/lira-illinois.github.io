---
title: "A Survey of Inverse Reinforcement Learning in Aviation and Future Outlooks"
date: 2026-02-01
imageUrl: '/src/assets/research/irl.png'
imageAlt: "Urban air mobility is an application of interest for CAAMS."
funding: "NASA 80NSSC23M0221 and ONR N00014-20-1-2249"
fundingSlugs: ["nasa.jpg", "onr.png"]
citation: "JAIS'26"
projects: ["cams"]
paperUrl: '/files/jais-irl.pdf'
---

<!-- <figure-full-caption-very-large>
	<a href="{{ site.url }}{{ site.baseurl }}/assets/images/research/aviation-irl.png"><img src="{{ site.url }}{{ site.baseurl }}/assets/images/research/aviation-irl.png"></a>
	<figcaption>Our work was motivated by the finding that the use of IRL for aviation has not followed trends seen in other domains like autonomous vehicles. This figure shows the number of IRL papers published across engineering and specifically in aerospace engineering. Data was retrieved from Dimensions, a database of research articles indexed via Crossref, PubMed, PubMed Central, arXiv.org and more than 160 publishers directly. Papers counted here include those containing the key phrase “inverse reinforcement learning.” Aerospace engineering papers were filtered using Dimension’s research area subcategory “Aerospace Engineering.</figcaption>
</figure-full-caption-very-large> -->

This work surveys current applications of inverse reinforcement learning (IRL) in aviation. We also identify potential challenges of using IRL for aviation, which may explain its current limited use within the field, and identify potential future applications of IRL for aviation. See our 2025 AIAA SciTech Forum paper for more details.

<!-- <div class="row">
    <a href="https://arc.aiaa.org/doi/10.2514/6.2025-1540" class="button_general">DOI</a>
</div> -->