---
title: "On Generating Explanations for Reinforcement Learning Policies: An Empirical Study"
date: 2024-12-17
imageUrl: '/src/assets/research/tl-search.png'
imageAlt: "An example output of our tree search method."
funding: "ONR N00014-20-1-2249"
fundingSlugs: ["onr.png"]
citation: "L-CSS'24"
projects: ["explainable-verifiable-learning"]
paperUrl: '/files/tl-search.pdf'
---

<!-- <figure-full-caption>
	<a href="{{ site.url }}{{ site.baseurl }}/assets/images/research/lcss-search.png"><img src="{{ site.url }}{{ site.baseurl }}/assets/images/research/lcss-search.png"></a>
	<figcaption>A partial trace of our search method with weighted Kullback-Leibler (KL) divergence values used to determine which nodes to expand.</figcaption>
</figure-full-caption> -->

This work proposes a greedy search over a class of **temporal logic formulae** to infer human-interpretable explanations of reinforcement learning policies. See our IEEE Control Systems Letters paper for more details.

<!-- <div class="row">
	<a href="https://arxiv.org/pdf/2309.16960" class="button_general">arXiv</a>
	<a href="https://doi.org/10.1109/LCSYS.2024.3519301" class="button_general">DOI</a>
</div> --> -->